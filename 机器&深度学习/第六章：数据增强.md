
#### 算法介绍

在图像分类任务中，图像数据的增广是一种常用的正则化方法，常用于数据量不足或者模型参数较多的场景。在本章节中，我们将对除 ImageNet 分类任务标准数据增强外的 8 种数据增强方式进行简单的介绍和对比，用户也可以将这些增广方法应用到自己的任务中，以获得模型精度的提升。这 8 种数据增强方式在 ImageNet 上的精度指标如下所示。


![](./imgs/main_image_aug.png)


#### paddle.vision.transforms

**亮度调节**
```
import numpy as np
from PIL import Image
from paddle.vision.transforms import functional as F

img_path = "/home/aistudio/work/cat.jpg"

image=Image.open(img_path)

# adjust_brightness对输入图像进行亮度值调整
new_img = F.adjust_brightness(image, 0.4)
```

<center style='display: flex'><div><img src='./imgs/cat01.png'></div><div><img src='./imgs/cat02.png'></div></center>


**色调调整**

```
# adjust_hue对输入图像进行色调的调整
F.adjust_hue(image, 0.1)
```

<center style='display: flex'><div><img src='./imgs/cat01.png'></div><div><img src='./imgs/cat03.png'></div></center>


**随机旋转**

```
from paddle.vision.transforms import RandomRotation

img_path = "/home/aistudio/work/cat.jpg"

image=Image.open(img_path)

# RandomRotation依据90度，按照均匀分布随机产生一个角度对图像进行旋转
transform = RandomRotation(90)
new_img = transform(image)
```

<center style='display: flex'><div><img src='./imgs/cat01.png'></div><div><img src='./imgs/cat04.png'></div></center>




#### 数据增强简介

如果没有特殊说明，本章节中所有示例为 ImageNet 分类，并且假设最终输入网络的数据维度为：[batch-size, 3, 224, 224]

其中 ImageNet 分类训练阶段的标准数据增强方式分为以下几个步骤：

- 图像解码：简写为 ImageDecode
- 随机裁剪到长宽均为 224 的图像：简写为 RandCrop
- 水平方向随机翻转：简写为 RandFlip
- 图像数据的归一化：简写为 Normalize
- 图像数据的重排，[224, 224, 3] 变为 [3, 224, 224]：简写为 Transpose
- 多幅图像数据组成 batch 数据，如 batch-size 个 [3, 224, 224] 的图像数据拼组成 [batch-size, 3, 224, 224]：简写为 Batch

相比于上述标准的图像增广方法，研究者也提出了很多改进的图像增广策略，这些策略均是在标准增广方法的不同阶段插入一定的操作，基于这些策略操作所处的不同阶段，我们将其分为了三类：

- 对 RandCrop 后的 224 的图像进行一些变换: AutoAugment，RandAugment
- 对 Transpose 后的 224 的图像进行一些裁剪: CutOut，RandErasing，HideAndSeek，GridMask
- 对 Batch 后的数据进行混合: Mixup，Cutmix

增广后的可视化效果如下所示。

![](./imgs/image_aug_samples_s.jpg)


##### mixup

image mixup （图像混合） 以随机权重将两张图片混合起来，提高网络在空间上的抗干扰能力。以下图为例，将任意两张图片加权叠加作为输入，训练过程中使用的损失为两张图片的损失乘以各自权重的加和
    ![](./imgs/1ad5ad6eddc451dae2362a7f89877161d21632e6.webp)

```
  sample_transforms:
    - Decode: {}
    # 对图片做mixup增强,(2张图片合二为一) 处理后的类别（gt_score）
    - Mixup: {alpha: 1.5, beta: 1.5}  # beta分布
```

> cooc 数据集精度提升1% 左右


##### RandomDistort 随机颜色失真

- 色调、饱和度、对比度、亮度
- prob 概率默认为1 
```
hue=[-18, 18, 0.5],
saturation=[0.5, 1.5, 0.5],
contrast=[0.5, 1.5, 0.5],
brightness=[0.5, 1.5, 0.5],
```

##### RandomExpand 随机填充

- 最大膨胀比默认4。膨胀的概率默认0.5

![](./imgs/e28451783bb1697adf7c1383ec4d07cd.png)

```
  sample_transforms:
    # 将图像数据按照rgb格式转换为numpy格式
    - Decode: {}
    # 对图片做mixup增强,(2张图片合二为一) 处理后的类别（gt_score）
    - Mixup: {alpha: 1.5, beta: 1.5}
    # 随机颜色失真(色调、饱和度、对比度、亮度)
    - RandomDistort: {}
    # 随机填充 （最大膨胀比默认4。膨胀的概率默认0.5）
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
```

##### RandomCrop 随机裁剪

```
class RandomCrop(BaseOperator):
    def __init__(self,
                 aspect_ratio=[.5, 2.],
                 thresholds=[.0, .1, .3, .5, .7, .9],
                 scaling=[.3, 1.],
                 num_attempts=50,
                 allow_no_crop=True,
                 cover_all_box=False,
                 is_mask_crop=False,
                 ioumode="iou",
                 prob=1.0):
```
- aspect_ratio: 裁剪区域的纵横比。格式为[min， max]。
- thresholds: iou阈值用于确定有效的bbox裁剪
- scaling 裁剪区域与原始图像之间的比率（裁剪区域的宽和原图的宽、裁剪区域的高和原图的高）。格式为[min， max]
- num_attempts： 放弃前的尝试次数
- allow_no_crop： 允许返回而不实际裁剪它们
- cover_all_box： 确保所有的bbox都被覆盖在最后的裁剪中
- is_mask_crop： 是否裁剪分割
- prob： 随机概率 默认1


##### RandomFlip 随机反转
- prod 概率默认0.5

依概率水平（左右）翻转图片



##### BatchRandomResize

随机调整图像大小到目标大小。随机target_size和插值方法

- target_size: 如果random_size为真，随机到图像目标大小【必须是列表或元组】 例如：[320, 352, 384, 416, 448, 480, 512, 544, 576, 608]
- keep_ratio  是否保持比率  默认true
- random_interp 是否随机选择插值方法 默认false
- random_size 是否随机选择目标大小的图像 默认true

```
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608], random_size: True, random_interp: True, keep_ratio: False}
```

##### NormalizeBox

- box 坐标归一化 将边界框（gt_bbox）的坐标转换为(0,1)，仅仅YOLO系列算法需要

```
- NormalizeBox: {}
```


##### PadBox

 如果 gt_bboxes 数量小于 num_max_boxes (默认50)，填充值为0的 box，仅仅YOLO系列算法需要


```
- PadBox: {num_max_boxes: 50}
```

##### BboxXYXY2XYWH

坐标格式转化，从XYXY转成XYWH，仅仅YOLO系列算法需要

```
- BboxXYXY2XYWH: {}
```

##### NormalizeImage

- is_scale 将像素值缩放到[0,1], 默认true

归一化 这里得到的img数据数值需要调整，需要除以255，并且减去均值和除以方差

```
- NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: True}
```

##### Permute

将维度从[H, W, C]调整为[C, H, W]

```
- Permute: {}
```

##### Gt2YoloTarget

根据真值数据生成YOLOv3目标，此操作符仅用于细粒度YOLOv3 loss模式

- downsample_ratios 下采样倍率 [32,16,8]
- anchor_masks  anchor 索引
- anchors： 不同倍率下的anchor大小[w,h]

```
- Gt2YoloTarget: {anchor_masks: [[6, 7, 8], [3, 4, 5], [0, 1, 2]], anchors: [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]], downsample_ratios: [32, 16, 8]}
```

#### Mosaic数据增强

Mosaic数据增强。Mosaic是参考2019年提出的CutMix数据增强的方式，但CutMix只使用了两张图片进行拼接，而Mosaic数据增强则采用了4张图片，随机缩放，随机裁剪，随机排布的方式进行拼接 。这样使得模型更获得更多相关或不相关的上下文信息，学习到更加鲁棒的特征。

![](./imgs/v2-8be87d4bb6eb631c0d4d13181e5fc010_720w.webp)


#### 图像变换类

图像变换类指的是对 RandCrop 后的 224 的图像进行一些变换，主要包括
- AutoAugment
- RandAugment
- TimmAutoAugment

**AutoAugment 算法介绍**
论文地址：https://arxiv.org/abs/1805.09501v1

开源代码 github 地址：https://github.com/DeepVoltaire/AutoAugment

不同于常规的人工设计图像增广方式，AutoAugment 是在一系列图像增广子策略的搜索空间中通过搜索算法找到的适合特定数据集的图像增广方案。针对 ImageNet 数据集，最终搜索出来的数据增强方案包含 25 个子策略组合，每个子策略中都包含两种变换，针对每幅图像都随机的挑选一个子策略组合，然后以一定的概率来决定是否执行子策略中的每种变换。

经过 AutoAugment 数据增强后结果如下图所示。

![](./imgs/test_autoaugment.jpeg)

**AutoAugment 配置**
AotoAugment 的图像增广方式的配置如下。AutoAugment 是在 uint8 的数据格式上转换的，所以其处理过程应该放在归一化操作(NormalizeImage)之前

```
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
        - RandFlipImage:
            flip_code: 1
        - AutoAugment:
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
```

**RandAugment 算法介绍**

论文地址：https://arxiv.org/pdf/1909.13719.pdf

开源代码 github 地址：https://github.com/heartInsert/randaugment

AutoAugment 的搜索方法比较暴力，直接在数据集上搜索针对该数据集的最优策略，其计算量很大。在 RandAugment 文章中作者发现，一方面，针对越大的模型，越大的数据集，使用 AutoAugment 方式搜索到的增广方式产生的收益也就越小；另一方面，这种搜索出的最优策略是针对该数据集的，其迁移能力较差，并不太适合迁移到其他数据集上。

在 RandAugment 中，作者提出了一种随机增广的方式，不再像 AutoAugment 中那样使用特定的概率确定是否使用某种子策略，而是所有的子策略都会以同样的概率被选择到，论文中的实验也表明这种数据增强方式即使在大模型的训练中也具有很好的效果。

经过 RandAugment 数据增强后结果如下图所示。

![](./imgs/test_randaugment.jpeg)


**RandAugment 配置**

RandAugment 的图像增广方式的配置如下，其中用户需要指定其中的参数 num_layers 与 magnitude，默认的数值分别是 2 和 5。RandAugment 是在 uint8 的数据格式上转换的，所以其处理过程应该放在归一化操作(NormalizeImage)之前。

```
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
        - RandFlipImage:
            flip_code: 1
        - RandAugment:
            num_layers: 2
            magnitude: 5
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
```

**TimmAutoAugment 算法介绍**

开源代码 github 地址：https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/auto_augment.py

TimmAutoAugment 是开源作者对 AutoAugment 和 RandAugment 的改进，事实证明，其在很多视觉任务上有更好的表现，目前绝大多数 VisionTransformer 模型都是基于 TimmAutoAugment 去实现的。

**TimmAutoAugment 配置**
TimmAutoAugment 的图像增广方式的配置如下，其中用户需要指定其中的参数 config_str、interpolation、img_size，默认的数值分别是 rand-m9-mstd0.5-inc1、bicubic、224。TimmAutoAugment 是在 uint8 的数据格式上转换的，所以其处理过程应该放在归一化操作(NormalizeImage)之前。

```
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
        - RandFlipImage:
            flip_code: 1
        - TimmAutoAugment:
            config_str: rand-m9-mstd0.5-inc1
            interpolation: bicubic
            img_size: 224
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
```

#### 图像裁剪类


图像裁剪类主要是对 Transpose 后的 224 的图像进行一些裁剪，并将裁剪区域的像素值置为特定的常数（默认为 0），主要包括：

- CutOut
- RandErasing
- HideAndSeek
- GridMask

图像裁剪的这些增广并非一定要放在归一化之后，也有不少实现是放在归一化之前的，也就是直接对 uint8 的图像进行操作，两种方式的差别是：如果直接对 uint8 的图像进行操作，那么再经过归一化之后被裁剪的区域将不再是纯黑或纯白（减均值除方差之后像素值不为 0）。而对归一后之后的数据进行操作，裁剪的区域会是纯黑或纯白。

上述的裁剪变换思路是相同的，都是为了解决训练出的模型在有遮挡数据上泛化能力较差的问题，不同的是他们的裁剪方式、区域不太一样。


**Cutout 算法介绍**

论文地址：https://arxiv.org/abs/1708.04552

开源代码 github 地址：https://github.com/uoguelph-mlrg/Cutout

Cutout 可以理解为 Dropout 的一种扩展操作，不同的是 Dropout 是对图像经过网络后生成的特征进行遮挡，而 Cutout 是直接对输入的图像进行遮挡，相对于 Dropout 对噪声的鲁棒性更好。作者在论文中也进行了说明，这样做法有以下两点优势：(1)通过 Cutout 可以模拟真实场景中主体被部分遮挡时的分类场景；(2)可以促进模型充分利用图像中更多的内容来进行分类，防止网络只关注显著性的图像区域，从而发生过拟合。

经过 RandAugment 数据增强后结果如下图所示。

![](./imgs/test_cutout.jpeg)

**Cutout 配置**

Cutout 的图像增广方式的配置如下，其中用户需要指定其中的参数 n_holes 与 length，默认的数值分别是 1 和 112。类似其他图像裁剪类的数据增强方式，Cutout 既可以在 uint8 格式的数据上操作，也可以在归一化)(NormalizeImage)后的数据上操作，此处给出的是在归一化后的操作。

```
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
        - RandFlipImage:
            flip_code: 1
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
        - Cutout:
            n_holes: 1
            length: 112
```

**RandomErasing 算法介绍**

论文地址：https://arxiv.org/pdf/1708.04896.pdf

开源代码 github 地址：https://github.com/zhunzhong07/Random-Erasing

RandomErasing 与 Cutout 方法类似，同样是为了解决训练出的模型在有遮挡数据上泛化能力较差的问题，作者在论文中也指出，随机裁剪的方式与随机水平翻转具有一定的互补性。作者也在行人再识别(REID)上验证了该方法的有效性。与 Cutout 不同的是，在 RandomErasing 中，图片以一定的概率接受该种预处理方法，生成掩码的尺寸大小与长宽比也是根据预设的超参数随机生成。

PaddleClas 中 RandomErasing 的使用方法如下所示。

经过 RandomErasing 数据增强后结果如下图所示。

![](./imgs/test_randomerassing.jpeg)

**RandomErasing 配置**

RandomErasing 的图像增广方式的配置如下，其中用户需要指定其中的参数 EPSILON、sl、sh、r1、attempt、use_log_aspect、mode，默认的数值分别是 0.25、0.02、1.0/3.0、0.3、10、True、pixel。类似其他图像裁剪类的数据增强方式，RandomErasing 既可以在 uint8 格式的数据上操作，也可以在归一化(NormalizeImage)后的数据上操作，此处给出的是在归一化后的操作。

```
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
        - RandFlipImage:
            flip_code: 1
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ''
        - RandomErasing:
            EPSILON: 0.25
            sl: 0.02
            sh: 1.0/3.0
            r1: 0.3
            attempt: 10
            use_log_aspect: True
            mode: pixel
```


https://github.com/PaddlePaddle/PaddleClas/blob/release/2.5.2/docs/zh_CN/training/config_description/data_augmentation.md




#### 图像分割数据增强
##### ResizeStepScaling

在一定范围内按比例缩放图像

- min_scale_factor（浮点数，可选）：最小缩放。默认值:0.75。
- max_scale_factor（浮点数，可选）：最大缩放比例。默认值:1.25。
- scale_step_size （float，可选）：缩放间隔。默认值:0.25。

```
num_steps = int((max_scale_factor-min_scale_factor) / scale_step_size + 1)
```


```
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
```

如上配置则 num_steps =7，则 scale_factors=np.linspace(0.5,2,7).tolist()=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0] 即在scale_factors中随机缩放

> 原始数据使用cv2.INTER_LINEAR方法缩放
> label 标签数据使用cv2.INTER_NEAREST方法缩放

![](./imgs/aa_1.png)


##### RandomPaddingCrop

从原始图像中裁剪子图像并随机注释图像。若为目标裁剪尺寸
大于原始图像，那么右下角内边距将被填充

- crop_size（元组，可选）：目标裁剪大小。默认值：（512,512）
- im_padding_value（浮点，可选）：原始图像的填充值。默认值:127.5。
- label_padding_value （int，可选）：标注图像的填充值。默认值:255。
- category_max_ratio（浮点数，可选）：单个类别可以占用的最大比率。默认值:1.0。
- ignore_index （int，可选）：注释图像中应该忽略的值。默认值:255。
- loop_times （int，可选）：尝试裁剪图像的最大次数。默认值:10

```
- type: RandomPaddingCrop
    crop_size: [128, 128]  # W, h
```

![](./imgs/randompaddingcrop_1.png)


##### RandomHorizontalFlip

以一定的概率水平翻转图像(prob=0.5)


##### RandomVerticalFlip

以一定的概率垂直翻转图像(prob=0.1)


##### RandomDistort 随机颜色失真

- 色调、饱和度、对比度、亮度 (默认概率都为0.5)， 清晰度的概率默认为0
- 色调的取值为[-18,18] 其它取值都为[1-0.5,1+0.5]  

```
    - type: RandomHorizontalFlip
    - type: RandomVerticalFlip
    - type: RandomDistort
      brightness_range: 0.4
      contrast_range: 0.4
      saturation_range: 0.4
```