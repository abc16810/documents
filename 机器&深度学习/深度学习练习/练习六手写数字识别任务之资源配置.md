####
# https://aistudio.baidu.com/projectdetail/8774861
####

从前几节的训练看，无论是房价预测任务还是MNIST手写字数字识别任务，训练好一个模型不会超过10分钟，主要原因是我们所使用的神经网络比较简单。但实际应用时，常会遇到更加复杂的机器学习或深度学习任务，需要运算速度更高的硬件（如GPU、NPU），甚至同时使用多个机器共同训练一个任务（多卡训练和多机训练）。本节我们依旧横向展开"横纵式"教学方法，如 图1 所示，探讨在手写数字识别任务中，通过资源配置的优化，提升模型训练效率的方法。

![](https://ai-studio-static-online.cdn.bcebos.com/37487ce3431a4632b2f2ee9269bdf6bc56f30cf6f2e34073887eb4056cb6c2e8)

#### 程序运行的全局设备

`paddle.device.get_device`功能返回当前程序运行的全局设备，返回的是一个类似于 `cpu、 gpu:x、 xpu:x` 或者 `npu:x` 字符串，如果没有设置全局设备，当cuda可用的时候返回 `gpu:0` ，当cuda不可用的时候返回 cpu 。由于GPU通常为多个计算卡的结构，返回结果`gpu:0`中冒号后面的0代表0号卡。如果是4卡的GPU，编号分别为0、1、2、3。


```
import paddle

device = paddle.device.get_device()

print("device:",device)
```
device: gpu:0

如果您启动项目时选用的是GPU，那么会输出device: `gpu:0`

在飞桨中，可通过place函数查看一个Tensor的设备位置。张量可能的设备位置有三种：CPU/GPU/固定内存，其中固定内存也称为不可分页内存或锁页内存， 其与GPU之间具有更高的读写效率，并且支持异步传输，这对网络整体性能会有进一步提升，但其缺点是分配空间过多时可能会降低主机系统的性能， 因为其减少了用于存储虚拟内存数据的可分页内存。

如果想将CPU上的Tensor拷贝到GPU上，通过cuda(device_id=None, blocking=False)函数完成。如果当前Tensor已经在GPU上，且device_id为None，则不会发生任何拷贝。具体参数说明如下：

- device_id (int, optional) - 目标GPU的设备Id，默认为None，此时为当前Tensor所在的设备Id，如果当前Tensor不在GPU上，则为0。
- blocking (bool, optional) - 如果为False并且当前Tensor处于固定内存上，将会发生主机到设备端的异步拷贝。否则，会发生同步拷贝。默认为False。

下面我们在CPU上创建一个Tensor，获取其设备位置，然后将该Tensor拷贝到GPU上，再次获取设备位置：

```
import paddle
x = paddle.to_tensor(1.0, place=paddle.CPUPlace())
print(x.place)        # CPUPlace

y = x.cuda()
print(y.place)        # CUDAPlace(0)
```

#### 单GPU训练

通过`paddle.device.set_device` API，设置在GPU上训练还是CPU上训练。

> paddle.device.set_device (device)

参数 device (str)：此参数确定特定的运行设备，可以是`cpu`、 `gpu:x`或者是`xpu:x`。其中，x是GPU或XPU的编号。当device是cpu时， 程序在CPU上运行；当device是gpu:x时，程序在GPU上运行。

```python
import paddle.nn.functional as F

#仅优化算法的设置有所差别
def train(model):
    #开启GPU
    use_gpu = True
    paddle.device.set_device('gpu:0') if use_gpu else paddle.device.set_device('cpu')
    model.train()
    ...
```
尝试把`use_gpu`设置成False，训练5个epoch需要的时间是GPU用时的10倍左右，可见GPU的并行能力要比CPU强大很多


#### 分布式训练

在工业实践中，很多较复杂的任务需要使用更强大的模型。强大模型加上海量的训练数据，经常导致模型训练耗时严重。比如在计算机视觉分类任务中，训练一个在ImageNet数据集上精度表现良好的模型，大概需要一周的时间，因为过程中我们需要不断尝试各种优化的思路和方案。如果每次训练均要耗时1周，这会大大降低模型迭代的速度。在机器资源充沛的情况下，建议采用分布式训练，大部分模型的训练时间可压缩到小时级别。

分布式训练有两种基本的实现模式：模型并行和数据并行。


**模型并行**

模型并行是将一个网络模型拆分为多份，拆分后的模型分到多个设备上（GPU）训练，每个设备的训练数据是相同的。模型并行的实现模式可以节省内存，但是应用较为受限。

模型并行的方式一般适用于如下两个场景：


- **模型架构过大**： 完整的模型无法放入单个GPU。如2012年ImageNet大赛的冠军模型AlexNet是模型并行的典型案例，由于当时GPU内存较小，单个GPU不足以承担AlexNet，因此研究者将AlexNet拆分为两部分放到两个GPU上并行训练。

- **网络模型的结构设计相对独立**： 当网络模型的设计结构可以并行化时，采用模型并行的方式。如在计算机视觉目标检测任务中，一些模型（如YOLO9000）的边界框回归和类别预测是独立的，可以将独立的部分放到不同的设备节点上完成分布式训练。


**数据并行**

数据并行与模型并行不同，数据并行每次读取多份数据，读取到的数据输入给多个设备（GPU）上的模型，每个设备上的模型是完全相同的，飞桨采用的就是这种方式。

> 当前GPU硬件技术快速发展，深度学习使用的主流GPU的内存已经足以满足大多数的网络模型需求，所以大多数情况下使用数据并行的方式。


数据并行的方式与众人拾柴火焰高的道理类似，如果把训练数据比喻为砖头，把一个设备（GPU）比喻为一个人，那单GPU训练就是一个人在搬砖，多GPU训练就是多个人同时搬砖，每次搬砖的数量倍数增加，效率呈倍数提升。值得注意的是，每个设备的模型是完全相同的，但是输入数据不同，因此每个设备的模型计算出的梯度是不同的。如果每个设备的梯度只更新当前设备的模型，就会导致下次训练时，每个模型的参数都不相同。因此我们还需要一个梯度同步机制，保证每个设备的梯度是完全相同的。

梯度同步有两种方式：PRC通信方式和NCCL2通信方式（Nvidia Collective multi-GPU Communication Library）。

PRC通信方式

PRC通信方式通常用于CPU分布式训练，它有两个节点：参数服务器Parameter server和训练节点Trainer，结构如 图2 所示。

![](https://ai-studio-static-online.cdn.bcebos.com/560af46fd88140e8bc357dfad0d21e547e4703073c834c6c99c342b79e5076e4)

parameter server收集来自每个设备的梯度更新信息，并计算出一个全局的梯度更新。Trainer用于训练，每个Trainer上的程序相同，但数据不同。当Parameter server收到来自Trainer的梯度更新请求时，统一更新模型的梯度

NCCL2通信方式（Collective）

当前飞桨的GPU分布式训练使用的是基于NCCL2的通信方式，结构如 图3 所示。

![](https://ai-studio-static-online.cdn.bcebos.com/a27f1873e4934a0f8cda436b33830268ef4621cf6b994deb839db0a272e75de1)


相比PRC通信方式，使用NCCL2（Collective通信方式）进行分布式训练，不需要启动Parameter server进程，每个Trainer进程保存一份完整的模型参数，在完成梯度计算之后通过Trainer之间的相互通信，Reduce梯度数据到所有节点的所有设备，然后每个节点在各自完成参数更新。

飞桨提供了便利的数据并行训练方式，用户只需要对程序进行简单修改，即可实现在多GPU上并行训练（NCCL2的通信方式）。接下来将讲述如何将一个单机程序通过简单的改造，变成单机多卡程序。

单机多卡程序通过如下两步改动即可完成：

1）初始化并行环境。

2）使用paddle.DataParallel封装模型。

后续通过启动时候指定运行程序的多个GPU卡，飞桨会自动切分数据进行多卡分布式训练，加速训练过程。

```python
import paddle 
import paddle.distributed as dist

def train_multi_gpu(model):
    # 修改1- 初始化并行环境
    dist.init_parallel_env()
    # 修改2- 增加paddle.DataParallel封装
    model = paddle.DataParallel(model)
    model.train()
    ...
```


**基于launch方式启动**

单机单卡启动，默认使用第0号卡。
```
python train.py
```
单机多卡启动，默认使用当前可见的所有卡。
```
python -m paddle.distributed.launch train.py
```
单机多卡启动，设置当前使用的第0号和第1号卡。
```
python -m paddle.distributed.launch --gpus '0,1' --log_dir ./mylog train.py
```

```
$ export CUDA_VISIABLE_DEVICES='0,1'
$ python -m paddle.distributed.launch train.py
```